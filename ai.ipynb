{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "import torch.optim as optim\n",
    "import spacy\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "import torch.nn as nn\n",
    "from torchtext.data import Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from tensorboard) (1.67.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from tensorboard) (3.7)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from tensorboard) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from tensorboard) (5.28.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from tensorboard) (72.1.0)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from tensorboard) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext==0.6.0 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (0.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext==0.6.0 --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: utils in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (1.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from spacy) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from spacy) (8.3.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from spacy) (0.15.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from spacy) (4.67.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from spacy) (2.11.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from spacy) (72.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.0)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from jinja2->spacy) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\lenovo\\anaconda3\\envs\\cuda_env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting de-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.8.0/de_core_news_sm-3.8.0-py3-none-any.whl (14.6 MB)\n",
      "     ---------------------------------------- 0.0/14.6 MB ? eta -:--:--\n",
      "     ---- ----------------------------------- 1.6/14.6 MB 12.0 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 3.4/14.6 MB 10.1 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 4.7/14.6 MB 8.7 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 6.6/14.6 MB 8.8 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 8.7/14.6 MB 8.7 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 10.2/14.6 MB 8.6 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 11.3/14.6 MB 8.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 12.6/14.6 MB 7.8 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 13.9/14.6 MB 7.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 14.6/14.6 MB 7.7 MB/s eta 0:00:00\n",
      "Installing collected packages: de-core-news-sm\n",
      "Successfully installed de-core-news-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('de_core_news_sm')\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ----- ---------------------------------- 1.8/12.8 MB 10.1 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 3.9/12.8 MB 10.2 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 5.8/12.8 MB 9.8 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 7.3/12.8 MB 9.3 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.4/12.8 MB 9.5 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.8/12.8 MB 9.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 9.8 MB/s eta 0:00:00\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download de_core_news_sm\n",
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German and English Spacy models loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "spacy_ger = spacy.load(\"de_core_news_sm\")\n",
    "spacy_eng = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "print(\"German and English Spacy models loaded successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load German and English tokenizers from spaCy\n",
    "spacy_de = spacy.load(\"de_core_news_sm\")  # German tokenizer\n",
    "spacy_en = spacy.load(\"en_core_web_sm\")   # English tokenizer\n",
    "\n",
    "# Define tokenization functions\n",
    "def tokenize_ger(text):\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "def tokenize_eng(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "# Now define the fields\n",
    "german = Field(tokenize=tokenize_ger, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "english = Field(tokenize=tokenize_eng, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.6.0'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchtext.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/train.de.gz...\n",
      "Downloading https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/train.en.gz...\n",
      "Downloading https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/val.de.gz...\n",
      "Downloading https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/val.en.gz...\n",
      "Downloading https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/test_2016_flickr.de.gz...\n",
      "Downloading https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/test_2016_flickr.en.gz...\n",
      "All files downloaded and extracted successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "os.makedirs(\".data/multi30k\", exist_ok=True)\n",
    "\n",
    "base_url = \"https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/\"\n",
    "\n",
    "files = {\n",
    "    \"train.de\": \"train.de.gz\",\n",
    "    \"train.en\": \"train.en.gz\",\n",
    "    \"val.de\": \"val.de.gz\",\n",
    "    \"val.en\": \"val.en.gz\",\n",
    "    \"test.de\": \"test_2016_flickr.de.gz\",\n",
    "    \"test.en\": \"test_2016_flickr.en.gz\"\n",
    "}\n",
    "\n",
    "# Download and unzip\n",
    "for filename, gzipped in files.items():\n",
    "    url = base_url + gzipped\n",
    "    local_gz_path = f\".data/multi30k/{gzipped}\"\n",
    "    local_txt_path = f\".data/multi30k/{filename}\"\n",
    "\n",
    "    print(f\"Downloading {url}...\")\n",
    "    urllib.request.urlretrieve(url, local_gz_path)\n",
    "\n",
    "    # Unzip the .gz file\n",
    "    import gzip\n",
    "    with gzip.open(local_gz_path, 'rt', encoding='utf-8') as f_in:\n",
    "        with open(local_txt_path, 'w', encoding='utf-8') as f_out:\n",
    "            f_out.write(f_in.read())\n",
    "\n",
    "    # Remove .gz file to save space\n",
    "    os.remove(local_gz_path)\n",
    "\n",
    "print(\"All files downloaded and extracted successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Renamed test files successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.rename(\".data/multi30k/test.de\", \".data/multi30k/test2016.de\")\n",
    "os.rename(\".data/multi30k/test.en\", \".data/multi30k/test2016.en\")\n",
    "\n",
    "print(\" Renamed test files successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = Multi30k.splits(\n",
    "    exts=(\".de\", \".en\"),\n",
    "    fields=(german, english)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "german.build_vocab(train_data,max_size = 10000, min_freq =2)\n",
    "english.build_vocab(train_data, max_size = 10000, min_freq = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            embedding_size,\n",
    "            src_vocab_size,\n",
    "            trg_vocab_size,\n",
    "            src_pad_idx,\n",
    "            num_heads,\n",
    "            num_encoder_layers,\n",
    "            num_decoder_layers,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "            max_len,\n",
    "            device,\n",
    "    ):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.src_word_embedding = nn.Embedding(src_vocab_size, embedding_size)\n",
    "        self.src_position_embedding = nn.Embedding(max_len, embedding_size)\n",
    "        self.trg_word_embedding = nn.Embedding(trg_vocab_size, embedding_size)\n",
    "        self.trg_position_embedding = nn.Embedding(max_len, embedding_size)\n",
    "        self.device = device\n",
    "        self.transformer = nn.Transformer(\n",
    "            embedding_size,\n",
    "            num_heads,\n",
    "            num_encoder_layers,\n",
    "            num_decoder_layers,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "        )\n",
    "        self.fc_out = nn.Linear(embedding_size, trg_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "    def make_src_mask(self, src):\n",
    "        # src shape: (src_len, N)\n",
    "        src_mask = src.transpose(0, 1)  == self.src_pad_idx\n",
    "        # (N, src_len)\n",
    "        return src_mask\n",
    "        \n",
    "    def forward(self, src, trg):\n",
    "        src_seq_length, N = src.shape\n",
    "        trg_seq_length, N = trg.shape\n",
    "        src_positions = (\n",
    "            torch.arange(0, src_seq_length).unsqueeze(1).expand(src_seq_length,N).to(self.device)\n",
    "        )\n",
    "        trg_positions = (\n",
    "            torch.arange(0, trg_seq_length).unsqueeze(1).expand(trg_seq_length,N).to(self.device)\n",
    "        )\n",
    "        embed_src = self.dropout(\n",
    "            (self.src_word_embedding(src)+ self.src_position_embedding(src_positions))\n",
    "        )\n",
    "        embed_trg = self.dropout(\n",
    "            self.trg_word_embedding(trg)+self.trg_position_embedding(trg_positions)\n",
    "        )\n",
    "        src_padding_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.transformer.generate_square_subsequent_mask(trg_seq_length).to(self.device)\n",
    "\n",
    "        out = self.transformer(\n",
    "            embed_src,\n",
    "            embed_trg,\n",
    "            src_key_padding_mask = src_padding_mask,\n",
    "            tgt_mask = trg_mask\n",
    "        )\n",
    "        out = self.fc_out(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(model, sentence, german, english, device, max_length=50):\n",
    "    model.eval()\n",
    "\n",
    "    # Tokenize using spaCy\n",
    "    tokens = [tok.text.lower() for tok in spacy_ger(sentence)]\n",
    "    tokens = ['<sos>'] + tokens + ['<eos>']\n",
    "\n",
    "    # Convert tokens to indices\n",
    "    src_indexes = [german.vocab.stoi[token] for token in tokens]\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        src_mask = model.make_src_mask(src_tensor)\n",
    "        enc_src = model.transformer.encoder(\n",
    "            model.dropout(model.src_word_embedding(src_tensor) +\n",
    "                          model.src_position_embedding(torch.arange(0, src_tensor.shape[0]).unsqueeze(1).to(device))),\n",
    "            src_key_padding_mask=src_mask\n",
    "        )\n",
    "\n",
    "    outputs = [english.vocab.stoi[\"<sos>\"]]\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        trg_tensor = torch.LongTensor(outputs).unsqueeze(1).to(device)\n",
    "\n",
    "        trg_mask = model.transformer.generate_square_subsequent_mask(trg_tensor.shape[0]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model.transformer.decoder(\n",
    "                model.dropout(model.trg_word_embedding(trg_tensor) +\n",
    "                              model.trg_position_embedding(torch.arange(0, trg_tensor.shape[0]).unsqueeze(1).to(device))),\n",
    "                enc_src,\n",
    "                tgt_mask=trg_mask,\n",
    "                memory_key_padding_mask=src_mask\n",
    "            )\n",
    "\n",
    "            out = model.fc_out(out)\n",
    "            best_guess = out.argmax(2)[-1, :].item()\n",
    "            outputs.append(best_guess)\n",
    "\n",
    "            if best_guess == english.vocab.stoi[\"<eos>\"]:\n",
    "                break\n",
    "\n",
    "    translated_tokens = [english.vocab.itos[idx] for idx in outputs]\n",
    "    return translated_tokens[1:]  # remove <sos>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available()else \"cpu\")\n",
    "print(device)\n",
    "load_model= False\n",
    "save_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "num_epochs = 5\n",
    "learning_rate = 3e-4\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Model hyperparameters\n",
    "src_vocab_size = len(german.vocab)\n",
    "trg_vocab_size = len(english.vocab)\n",
    "embedding_size = 512\n",
    "num_heads = 8\n",
    "num_encoder_layers = 3\n",
    "num_decoder_layers = 3\n",
    "dropout = 0.10\n",
    "max_len = 100\n",
    "forward_expansion = 4\n",
    "src_pad_idx = english.vocab.stoi[\"<pad>\"]\n",
    "\n",
    "# Tensorboard for nice plots \n",
    "writer = SummaryWriter(\"run/loss_plots\")\n",
    "step = 0\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_sizes=(batch_size,batch_size,batch_size),\n",
    "    sort_within_batch = True,\n",
    "    sort_key = lambda x: len(x.src),\n",
    "    device = device,\n",
    "\n",
    ")\n",
    "model = Transformer(\n",
    "    embedding_size,\n",
    "    src_vocab_size,\n",
    "    trg_vocab_size,\n",
    "    src_pad_idx,\n",
    "    num_heads,\n",
    "    num_encoder_layers,\n",
    "    num_decoder_layers,\n",
    "    forward_expansion,\n",
    "    dropout,\n",
    "    max_len,\n",
    "    device,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "pad_idx = english.vocab.stoi[\"<pad>\"]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "\n",
    "\n",
    "if load_model:\n",
    "    load_checkpoint(torch.load(\"my_checkpoint.pth.ptar\"), model, optimizer)\n",
    "sentence = \"ein pferd geht unter einer brucke neben einmen boot.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def save_checkpoint(checkpoint, filename=\"my_checkpoint.pth.tar\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(checkpoint, filename)\n",
    "\n",
    "def load_checkpoint(checkpoint_file, model, optimizer):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    checkpoint = torch.load(checkpoint_file, map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/5]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence:\n",
      "dancer dancer dancer dancer dancer dancer dancer dancer dancer dancer dancer dancer dancer dancer dancer dancer dancer dancer dancer dancer dancer dancer dancer dancer driving dancer dancer dancer driving dancer dancer dancer dancer dancer dancer ways dancer dancer driving vegetable dancer dancer dancer dancer dancer dancer dancer dancer dancer dancer dancer dancer dancer dancer dancer dancer dancer dancer beside dancer dancer dancer beside dancer dancer dancer dancer dancer dancer dancer dancer dancer beside dancer dancer follows dancer dancer dancer hanging dancer dancer wavy dancer dancer dancer ways dancer dancer rig ways dancer dancer ways dancer dancer dancer follows beside dancer\n",
      "[Epoch 1/5]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence:\n",
      "a horse walks under a <unk> next to a <unk> . <eos>\n",
      "[Epoch 2/5]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence:\n",
      "a horse is walking under a <unk> next to a boat . <eos>\n",
      "[Epoch 3/5]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence:\n",
      "a horse walks under a dock next to a dock next to a boat . <eos>\n",
      "[Epoch 4/5]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence:\n",
      "a horse walks under a <unk> dock next to a <unk> boat . <eos>\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f\"[Epoch {epoch}/{num_epochs}]\")\n",
    "    if save_model:\n",
    "        checkpoint = {\n",
    "            \"state_dict\" : model.state_dict(),\n",
    "            \"optimizer\" : optimizer.state_dict(),\n",
    "        }\n",
    "        save_checkpoint(checkpoint)\n",
    "    model.eval()\n",
    "    translated_output = translate_sentence(\n",
    "\n",
    "        model, sentence, german, english, device, max_length=100\n",
    "\n",
    "        )\n",
    "    print(f\"Translated example sentence:\\n{' '.join(translated_output)}\")\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, batch in enumerate(train_iterator):\n",
    "        inp_data = batch.src.to(device)\n",
    "        target = batch.trg.to(device)\n",
    "        # forward prop\n",
    "        output = model(inp_data, target[:-1])\n",
    "        output = output.reshape(-1, output.shape[2])\n",
    "        target = target[1:].reshape(-1)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm = 1)\n",
    "        optimizer.step()\n",
    "        writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
    "        step +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "def bleu(data, model, german, english, device):\n",
    "    \"\"\"Calculates BLEU score for the given dataset\"\"\"\n",
    "    targets = []\n",
    "    outputs = []\n",
    "\n",
    "    for example in data:\n",
    "        src = vars(example)[\"src\"]\n",
    "        trg = vars(example)[\"trg\"]\n",
    "\n",
    "        # Convert src tokens back into a sentence\n",
    "        src_sentence = \" \".join(src)\n",
    "\n",
    "        # Translate the sentence\n",
    "        translated_tokens = translate_sentence(model, src_sentence, german, english, device)\n",
    "        translated_tokens = translated_tokens[:-1]  # remove <eos>\n",
    "\n",
    "        targets.append([trg])\n",
    "        outputs.append(translated_tokens)\n",
    "\n",
    "    return bleu_score(outputs, targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.metrics import bleu_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu score33.20\n"
     ]
    }
   ],
   "source": [
    "score = bleu(test_data, model, german, english, device)\n",
    "print(f\"Bleu score{score*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
